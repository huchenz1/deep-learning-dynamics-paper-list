# deep-learning-dynamics-paper-list

This is a list of peer-reviewed representative papers on deep learning dynamics. We hope to enjoy the grand adventure of exploring deep learning dynamics with more researchers. Corrections and suggestions are welcomed. 

# Introduction

The success of deep learning attributes to both deep network architecture and stochastic optimization. Understanding optimization dynamics of neural networks, namely deep learning dynamics, is a key challenge in theoretical foundations of deep learning and a promosing way to further improve empirical success of deep learning. A large body of related works have been published on top machine learning conferences and journals. However, a lterature review in this line of research is largely missing. It is highly valuable to continuously collect and share these great works. This is the purpose of this paper list. 

The paper list mainly includes four directions:
(1) Learning Dynamics of SGD,
(2) Learning Dynmaics of Adaptive Gradient Methods,
(3) Learning Dynamics with Training Techniques (e.g. Weight Decay, Normalization Layers, Gradient Clipping, etc.),
(4) Learning Dynamics beyond Standard Training (e.g. Bayesian Inference, Vicinal Risk Minimization, Private Training, etc.).


# Learning Dynamics of SGD

- A diffusion theory for deep learning dynamics: Stochastic gradient descent exponentially favors flat minima. In *ICLR 2021*. [[pdf](https://openreview.net/pdf?id=wXgk_iCiYGo)]

# Learning Dynmaics of Adaptive Gradient Methods


# Learning Dynamics with Training Techniques


# Learning Dynamics with Training Techniques






